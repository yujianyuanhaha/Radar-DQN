<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta name="keywords" content="Markov decision process, Toolbox, MATLAB">
   <title> mdp_eval_policy_TD_0 description </title>
</head>
<body bgcolor="#FFFFFF">

<center><table BORDER=0 CELLSPACING=0 CELLPADDING=0 COLS=2 WIDTH="100%" BGCOLOR="#FFFFCC" NOSAVE >
<tr BGCOLOR="#FFFFCC" NOSAVE>
<td BGCOLOR="#FFFFCC" NOSAVE><b>MDP Toolbox for MATLAB</b></td>
<td><div align=right><a href="DOCUMENTATION.html"><img SRC="arrow.gif" height=23 width=26></a></div></td>
</tr>
</table></center>

<p><b><font color="#FF0000"><font size=+2>mdp_eval_policy_TD_0</font></font></b>
<p><font color="#000000">Evaluates a policy using the TD(0) algorithm.</font>


<p><b><font color="#3366FF"><font size=+1>Syntax</font></font></b>
<font color="#000000">
<p>Vpolicy = mdp_eval_policy_TD_0 (P, R, discount, policy)<br>
Vpolicy = mdp_eval_policy_TD_0 (P, R, discount, policy, N)<br>
</font>

<p><b><font color="#3366FF"><font size=+1>Description</font></font></b>
<font color="#000000">
<p>mdp_eval_policy_TD_0 evaluates the value fonction associated to a policy using the TD(0) algorithm (Reinforcement Learning).
</font>

<p><b><font color="#3366FF"><font size=+1>Arguments</font></font></b>
<font color="#000000">
<ul><li><b>P : </b>transition probability array.</li></ul>
P can be a 3 dimensions array (SxSxA) or a cell array (1xA), each cell containing a sparse matrix (SxS).
<ul><li><b>R : </b>reward array.</li></ul>
R can be a 3 dimensions array (SxSxA) or a cell array (1xA), each cell containing a sparse matrix (SxS) or a 2D array (SxA) possibly sparse.
<ul><li><b>discount : </b>discount factor.</li></ul>
 discount is a real which belongs to [0; 1].
<ul><li><b>policy : </b>a policy.</li></ul>
policy is a (Sx1) vector. Each element is an integer corresponding to an action.
<ul><li><b>N (optional) : </b>number of iterations to perform.</li></ul>
N is an integer greater than the default value.<br>
By default, N is set to 10000.
</font>

<p><b><font color="#3366FF"><font size=+1>Evaluation</font></font></b>
<font color="#000000">
<ul><li><b>Vpolicy :</b> value fonction.</li></ul>
Vpolicy is a (Sx1) vector.
</font>

<p><b><font color="#3366FF"><font size=+1>Example</font></font></b>
<p><font color="#000000">
>> % To be able to reproduce the following example, it is necessary to initialize the pseudorandom number generator<br>
>> rand('seed',0) <br>
<br>
>> P(:,:,1) = [ 0.5 0.5; &nbsp 0.8 0.2 ];<br>
>> P(:,:,2) = [ 0   1; &nbsp 0.1 0.9 ];<br>
>> R = [ 5 10; &nbsp -1 2 ];<br><br>

>> Vpolicy = mdp_eval_policy_TD_0(P, R, 0.9, [1; 2])<br>
Vpolicy =<br>
&nbsp&nbsp   29.0357<br>
&nbsp&nbsp   24.2148<br>
<br>
In the above example, P can be a cell array containing sparse matrices:<br>
>> P{1} = sparse([ 0.5 0.5;&nbsp   0.8 0.2 ]);<br>
>> P{2} = sparse([ 0 1;&nbsp   0.1 0.9 ]);<br>
The function call is unchanged.<br>
</font>



<br><br>
<table BORDER=0 CELLSPACING=0 CELLPADDING=0 COLS=2 WIDTH="100%" BGCOLOR="#FFFFCC" NOSAVE >
<tr NOSAVE>
<td NOSAVE><b>MDP Toolbox for MATLAB</b></td>
<td><div align=right><a href="DOCUMENTATION.html"><img SRC="arrow.gif" height=23 width=26></a></div></td>
</tr>
</table>

<br>
<hr WIDTH="100%">
<br><font size=-1>MDPtoolbox/documentation/mdp_eval_policy_TD_0.html</font>
<br><font size=-1>Page created on August 31, 2009.</font>
</body>
</html>
